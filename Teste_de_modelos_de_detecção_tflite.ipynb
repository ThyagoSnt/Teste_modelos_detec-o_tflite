{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importando as bibliotecas e logando no drive:"
      ],
      "metadata": {
        "id": "CKhvybvPwQ3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VNavbF82vK8g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab9dac0b-e635-46a2-f431-1fc9d016bd87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importando as bibliotecas necessárias:\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "# Conectando ao Google Drive:\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções utilizadas:"
      ],
      "metadata": {
        "id": "746MgFbypi7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o modelo e suas informações da memória:\n",
        "def preparar_modelo(local):\n",
        "  # Carregar o modelo tflite escolhido da memória:\n",
        "  with open(local, 'rb') as f:\n",
        "      tflite_model = f.read()\n",
        "\n",
        "  # Instanciar um Interpretador\n",
        "  try:\n",
        "      interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "      interpreter.allocate_tensors()\n",
        "  except Exception as e:\n",
        "      print(\"Erro ao carregar o modelo:\", e)\n",
        "  else:\n",
        "      print(\"Modelo carregado com sucesso.\\n\")\n",
        "\n",
        "  # Preparar as Entradas:\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  input_shape = input_details[0]['shape']\n",
        "\n",
        "  return interpreter, input_details, output_details, input_shape"
      ],
      "metadata": {
        "id": "OW-WpXmXxNjq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para aplicar resize e normalizar a imagem para a entrada:\n",
        "def processamento_da_imagem(imagem, escala_x, escala_y):\n",
        "  # Redimensionar a imagem para as dimensões esperadas pelo modelo\n",
        "  resized_image = cv2.resize(imagem, (escala_x, escala_y))\n",
        "\n",
        "  # Converter de BGR para RGB (OpenCV carrega imagens como BGR por padrão)\n",
        "  new_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # Converter para ponto flutuante e normalizar\n",
        "  image_norm = new_image.astype(np.float32) / 255.0\n",
        "\n",
        "  # Transpor as dimensões para corresponder à forma esperada pelo modelo\n",
        "  image_norm = image_norm.transpose(2, 0, 1)\n",
        "\n",
        "  # Adicionar uma dimensão extra para corresponder à forma esperada pelo modelo\n",
        "  image_norm = np.expand_dims(image_norm, axis=0)\n",
        "\n",
        "  return image_norm, resized_image"
      ],
      "metadata": {
        "id": "0Dt6X-k5CPfO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para realizar inferência com o modelo tflite:\n",
        "def inferencia(image_norm, input_details, output_details, interpreter):\n",
        "  # Definir os dados de entrada do modelo\n",
        "  interpreter.set_tensor(input_details[0]['index'], image_norm)\n",
        "\n",
        "  # Realizando a inferência e computando o tempo decorrido\n",
        "  start = time.time()\n",
        "  interpreter.invoke()\n",
        "  end = time.time()\n",
        "  inference_time = end-start\n",
        "\n",
        "  # Obtendo os resultados da inferência\n",
        "  output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "  # Filtrando as linhas onde a probabilidade é significativa:\n",
        "  filtered_output_data = [detection for detection in output_data if detection[6] > 0.01]\n",
        "\n",
        "  return filtered_output_data, inference_time"
      ],
      "metadata": {
        "id": "SzGkQYXq0Xnf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_iou(caixa1, caixa2):\n",
        "    # Extrair coordenadas das caixas delimitadoras\n",
        "    x1_c1, y1_c1, largura_c1, altura_c1, _ = caixa1\n",
        "    x1_c2, y1_c2, largura_c2, altura_c2, _ = caixa2\n",
        "\n",
        "    # Calcular coordenadas dos vértices opostos\n",
        "    x2_c1 = x1_c1 + largura_c1\n",
        "    y2_c1 = y1_c1 + altura_c1\n",
        "    x2_c2 = x1_c2 + largura_c2\n",
        "    y2_c2 = y1_c2 + altura_c2\n",
        "\n",
        "    # Calcular coordenadas da interseção\n",
        "    x1_intersecao = max(x1_c1, x1_c2)\n",
        "    y1_intersecao = max(y1_c1, y1_c2)\n",
        "    x2_intersecao = min(x2_c1, x2_c2)\n",
        "    y2_intersecao = min(y2_c1, y2_c2)\n",
        "\n",
        "    # Calcular área de interseção\n",
        "    area_intersecao = max(0, x2_intersecao - x1_intersecao + 1) * max(0, y2_intersecao - y1_intersecao + 1)\n",
        "\n",
        "    # Calcular áreas das caixas delimitadoras\n",
        "    area_caixa1 = (x2_c1 - x1_c1 + 1) * (y2_c1 - y1_c1 + 1)\n",
        "    area_caixa2 = (x2_c2 - x1_c2 + 1) * (y2_c2 - y1_c2 + 1)\n",
        "\n",
        "    # Calcular área da união\n",
        "    area_uniao = area_caixa1 + area_caixa2 - area_intersecao\n",
        "\n",
        "    # Calcular IoU\n",
        "    iou = area_intersecao / area_uniao\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "kHnhwa4uUlrf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escreve as boxes na imagem e salva num caminho fixo\n",
        "def escreve_imagem_erro(img, lista_deteccoes, lista_rotulos, idx, tipo):\n",
        "  # Instânciando a variável fora do if\n",
        "  caminho_de_salvamento = 'none'\n",
        "\n",
        "  # Definindo o caminho de salvar o dado atual:\n",
        "  if tipo == 'erro':\n",
        "    caminho_de_salvamento = '/content/drive/MyDrive/yolo_pesos/falhas'\n",
        "  elif tipo == 'acerto':\n",
        "    caminho_de_salvamento = '/content/drive/MyDrive/yolo_pesos/acertos'\n",
        "\n",
        "  # Verifica se o diretório de salvamento existe, caso contrário, cria\n",
        "  if not os.path.exists(caminho_de_salvamento):\n",
        "      os.makedirs(caminho_de_salvamento)\n",
        "\n",
        "  # Itera sobre as lista de boxes e desenha cada uma na imagem\n",
        "  if len(lista_deteccoes) > 0:\n",
        "    for box in lista_deteccoes:\n",
        "      # Supondo que cada box seja uma tupla (x, y, largura, altura)\n",
        "      x, y, w, h, classe = box\n",
        "      # Desenha o retângulo na imagem\n",
        "      img = cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "      img = cv2.putText(img, f'detectado {classe}', (x, y + h + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  (255, 0, 0), 1)\n",
        "\n",
        "  if len(lista_rotulos) > 0:\n",
        "    for box in lista_rotulos:\n",
        "      # Supondo que cada box seja uma tupla (x, y, largura, altura)\n",
        "      x, y, w, h, classe = box\n",
        "      # Desenha o retângulo na imagem\n",
        "      img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "      img = cv2.putText(img, f'rotulo {classe}', (x, y + h + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,  (0, 255, 0), 1)\n",
        "\n",
        "  # Define o nome do arquivo de saída\n",
        "  caminho_completo = os.path.join(caminho_de_salvamento,  'exemplo_' + str(idx) + '.jpg')\n",
        "\n",
        "  # Salva a imagem com as boxes desenhadas\n",
        "  cv2.imwrite(caminho_completo, img)"
      ],
      "metadata": {
        "id": "ZPmuponJz7xu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def teste_modelo(diretorio_images, diretorio_labels, interpreter, input_details, output_details, input_shape, classes):\n",
        "  # Listar todos os arquivos no diretório\n",
        "  images = os.listdir(diretorio_images)\n",
        "  labels = os.listdir(diretorio_labels)\n",
        "\n",
        "  # Definindo as escalas das imagens de entrada\n",
        "  escala_x = int(input_shape[2])\n",
        "  escala_y = int(input_shape[3])\n",
        "\n",
        "  # Dicionário que guarda as métricas\n",
        "  metricas_classes = {}\n",
        "\n",
        "  # Inicializando as métricas das classes\n",
        "  for i in range(len(classes)):\n",
        "    metricas_classes[classes[i]] = {'TP': 0, 'FP': 0, 'FN': 0}\n",
        "\n",
        "  # Contagem de imagens exemplo:\n",
        "  imagens_erro_exemplo = 0\n",
        "  imagens_acerto_exemplo = 0\n",
        "\n",
        "  # Lista com todos os tempos de inferência:\n",
        "  tempos_de_inferencia = []\n",
        "\n",
        "  # Verificar se o número de imagens e rótulos é o mesmo\n",
        "  if len(images) != len(labels):\n",
        "      print(\"O número de imagens e rótulos não corresponde.\")\n",
        "  else:\n",
        "      # Loop sobre as imagens e rótulos ao mesmo tempo\n",
        "      for imagem_nome, label_nome in zip(images, labels):\n",
        "          # Caminhos completos para a imagem e o rótulo\n",
        "          caminho_imagem = os.path.join(diretorio_images, imagem_nome)\n",
        "          caminho_label = os.path.join(diretorio_labels, label_nome)\n",
        "\n",
        "          # Verificar se ambos são arquivos\n",
        "          if os.path.isfile(caminho_imagem) and os.path.isfile(caminho_label):\n",
        "              # Carregar a imagem usando OpenCV\n",
        "              imagem = cv2.imread(caminho_imagem)\n",
        "\n",
        "              # Verificar se a imagem foi carregada corretamente\n",
        "              if imagem is not None:\n",
        "                  # Processando a imagem:\n",
        "                  img_norm, img_resized = processamento_da_imagem(imagem, escala_x, escala_y)\n",
        "\n",
        "                  # Realizando a inferência:\n",
        "                  output, tempo_decorrido = inferencia(img_norm, input_details, output_details, interpreter)\n",
        "                  tempos_de_inferencia.append(tempo_decorrido)\n",
        "\n",
        "                  # Listas de detecções e rotulos da imagem atual:\n",
        "                  deteccoes = []\n",
        "                  rotulos = []\n",
        "\n",
        "                  for detection in output:\n",
        "                      # Obter os valores das coordenadas da bounding box:\n",
        "                      _, x1, y1, x2, y2, classe_pred, probabilidade_pred = detection\n",
        "\n",
        "                      # Corrigindo problemas de coordenadas fora da imagem:\n",
        "                      x1 = max(int(x1), 0)\n",
        "                      y1 = max(int(y1),0)\n",
        "                      x2 = min(int(x2), escala_x)\n",
        "                      y2 = min(int(y2), escala_y)\n",
        "\n",
        "                      # Calcular as dimensões da bounding box:\n",
        "                      bbox_largura = x2 - x1\n",
        "                      bbox_altura = y2 - y1\n",
        "\n",
        "                      # Salva a detecção atual na lista de detecções:\n",
        "                      deteccoes.append([x1, y1, int(bbox_largura), int(bbox_altura), int(classe_pred)])\n",
        "\n",
        "                  # Ler os rotulos do arquivo .txt:\n",
        "                  with open(caminho_label, 'r') as file:\n",
        "                    for linha in file:\n",
        "                        label_content = linha.strip()  # Remover espaços em branco extras\n",
        "                        valores = label_content.split() # Dividir o conteúdo em uma lista de valores\n",
        "\n",
        "                        # Converter os valores para os tipos apropriados\n",
        "                        classe = int(valores[0])\n",
        "                        centro_x = int(escala_x * float(valores[1]))\n",
        "                        centro_y = int(escala_y * float(valores[2]))\n",
        "                        largura = int(escala_x * float(valores[3]))\n",
        "                        altura = int(escala_y * float(valores[4]))\n",
        "                        x = centro_x - int(largura/2)\n",
        "                        y = centro_y - int(altura/2)\n",
        "\n",
        "                        # Salva a label atual na lista de rotulos:\n",
        "                        rotulos.append([int(x), int(y), int(largura), int(altura), int(classe)])\n",
        "\n",
        "                  # Cria cópias das listas:\n",
        "                  temp_detections = deteccoes.copy()\n",
        "                  temp_labels = rotulos.copy()\n",
        "\n",
        "                  # Verficação se ouver algum match\n",
        "                  img_match = 0\n",
        "\n",
        "                  # Realizando o matching das bbox e suas classificações:\n",
        "                  for detection in deteccoes:\n",
        "                    for label in rotulos:\n",
        "                      iou = calcular_iou(detection, label)\n",
        "                      if (iou > 0.5):\n",
        "                        # Verifica se a classe é igual:\n",
        "                        if (detection[4] == label[4]):\n",
        "                          img_match = 1\n",
        "                          metricas_classes[classes[detection[4]]]['TP'] += 1\n",
        "\n",
        "                          # Remove essas da lista pq são do mesmo objeto\n",
        "                          if detection in temp_detections:\n",
        "                            temp_detections.remove(detection)\n",
        "                          if label in temp_labels:\n",
        "                            temp_labels.remove(label)\n",
        "\n",
        "\n",
        "                  # Selecionando images que contem apenas erros:\n",
        "                  if img_match == 0 and len(temp_detections) > 0 or len(temp_labels) > 0:\n",
        "                    if imagens_erro_exemplo % 15 == 0:\n",
        "                      escreve_imagem_erro(img_resized, temp_detections, temp_labels, imagens_erro_exemplo, 'erro')\n",
        "                    imagens_erro_exemplo += 1\n",
        "\n",
        "                  # Selecionando images que contem apenas acertos:\n",
        "                  if img_match == 1 and len(temp_detections) == 0 and len(temp_labels) == 0:\n",
        "                    if imagens_acerto_exemplo % 35 == 0:\n",
        "                      escreve_imagem_erro(img_resized, deteccoes, rotulos, imagens_acerto_exemplo, 'acerto')\n",
        "                    imagens_acerto_exemplo += 1\n",
        "\n",
        "                  # Acessando cada detecção errada e associando a sua devida classe:\n",
        "                  for detection in temp_detections:\n",
        "                    metricas_classes[classes[detection[4]]]['FP'] += 1\n",
        "                  for label in temp_labels:\n",
        "                    metricas_classes[classes[label[4]]]['FN'] += 1\n",
        "\n",
        "              else:\n",
        "                print(f\"Não foi possível carregar a imagem: {caminho_imagem}\")\n",
        "          else:\n",
        "            print(f\"Arquivos ausentes para a imagem {imagem_nome} ou rótulo {label_nome}.\")\n",
        "\n",
        "  # Calculando as métricas do nosso teste:\n",
        "  num_imgs = len(images)\n",
        "  tempos_de_inferencia_medio = np.mean(tempos_de_inferencia)\n",
        "  tempo_inferencia_min = min(tempos_de_inferencia)\n",
        "  tempo_inferencia_max = max(tempos_de_inferencia)\n",
        "\n",
        "  # Exibindo as métricas e detalhes do teste:\n",
        "  print(\"Informações gerais do teste:\")\n",
        "  print(f\"Imagens inferidas: {num_imgs}\")\n",
        "  print(f\"Tempo de inferência Minimo: {tempo_inferencia_min:.2f}, Médio: {tempos_de_inferencia_medio:.2f}, Máximo: {tempo_inferencia_max:.2f}\")\n",
        "  print()\n",
        "  for i in range(len(classes)):\n",
        "      TP = metricas_classes[classes[i]]['TP']\n",
        "      FP = metricas_classes[classes[i]]['FP']\n",
        "      FN = metricas_classes[classes[i]]['FN']\n",
        "      precisao = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "      recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "      f1_score = 2 * (precisao * recall) / (precisao + recall) if (precisao + recall) > 0 else 0\n",
        "      print(f\"Métricas para a classe {classes[i]}:\")\n",
        "      print(f\"True positives: {TP}, False positives: {FP}, False negatives: {FN}\")\n",
        "      print(f\"Precisão: {precisao:.2f}\")\n",
        "      print(f\"Recall: {recall:.2f}\")\n",
        "      print(f\"Pontuação F1: {f1_score:.2f}\")\n",
        "      print()"
      ],
      "metadata": {
        "id": "oaqF_kzwyPEJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Realizando o teste:"
      ],
      "metadata": {
        "id": "W2Bt9MEFRomL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diretório contendo as imagens\n",
        "diretorio_images = '/content/drive/MyDrive/yolo_pesos/testes/testes/test_booleano/images'\n",
        "diretorio_labels = '/content/drive/MyDrive/yolo_pesos/testes/testes/test_booleano/labels'\n",
        "\n",
        "# Definindo onde está o nosso modelo:\n",
        "local_modelo_tflite = '/content/drive/MyDrive/yolo_pesos/booleano.tflite'\n",
        "\n",
        "# Preparando nosso modelo para o teste:\n",
        "modelo, input_details, output_details, input_shape = preparar_modelo(local_modelo_tflite)\n",
        "\n",
        "# Array das classes na ordem do treinamento:\n",
        "classes = ['benigno','maligno']\n",
        "\n",
        "# Testando:\n",
        "teste_modelo(diretorio_images, diretorio_labels, modelo, input_details, output_details, input_shape, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t3928mKzko4",
        "outputId": "c63e9e48-f007-445a-f492-f8103da0af06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo carregado com sucesso.\n",
            "\n",
            "Informações gerais do teste:\n",
            "Imagens inferidas: 205\n",
            "Tempo de inferência Minimo: 1.01, Médio: 1.11, Máximo: 2.17\n",
            "\n",
            "Métricas para a classe benigno:\n",
            "True positives: 83, False positives: 26, False negatives: 27\n",
            "Precisão: 0.76\n",
            "Recall: 0.75\n",
            "Pontuação F1: 0.76\n",
            "\n",
            "Métricas para a classe maligno:\n",
            "True positives: 83, False positives: 18, False negatives: 24\n",
            "Precisão: 0.82\n",
            "Recall: 0.78\n",
            "Pontuação F1: 0.80\n",
            "\n"
          ]
        }
      ]
    }
  ]
}